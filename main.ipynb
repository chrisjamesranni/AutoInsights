{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd2b2aab",
   "metadata": {},
   "source": [
    "# **INSTALLS AND PACKAGES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cacf2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK]  PyTorch loaded\n",
      "       CUDA available: False\n",
      "       Running on CPU\n",
      "Python version: 3.13.2\n",
      "Packages loaded successfully......!\n"
     ]
    }
   ],
   "source": [
    "import os, json, joblib, warnings, sys, time\n",
    "from pprint import pformat\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OneHotEncoder, PowerTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, StratifiedKFold, GroupKFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, classification_report, accuracy_score, f1_score\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression, ElasticNet, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.neural_network import MLPRegressor as SKMLPRegressor, MLPClassifier as SKMLPClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "USE_TORCH = False\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    from torch.utils.data import TensorDataset, DataLoader\n",
    "    USE_TORCH = True\n",
    "    TORCH_CUDA = torch.cuda.is_available()\n",
    "except Exception:\n",
    "    USE_TORCH = False\n",
    "    TORCH_CUDA = False\n",
    "\n",
    "if USE_TORCH:\n",
    "    print(f\"[OK]  PyTorch loaded\")\n",
    "    print(f\"       CUDA available: {TORCH_CUDA}\")\n",
    "    if TORCH_CUDA:\n",
    "        print(f\"       GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        print(\"       Running on CPU\")\n",
    "else:\n",
    "    print(\"[INFO] PyTorch not installed — using CPU-only sklearn MLP\")\n",
    "print(f\"Python version: {sys.version.split()[0]}\")\n",
    "\n",
    "print(f\"Packages loaded successfully......!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f15935",
   "metadata": {},
   "source": [
    "# **SETTINGS AND PATH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7b962a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_PATH:               Data/data.csv\n",
      "BEST_REGRESSOR_PATH:     models/best_regressor.joblib\n",
      "BEST_CLASSIFIER_PATH:    models/best_classifier.joblib\n",
      "LEADERBOARD_PATH:        reports/leaderboards.json\n",
      "\n",
      "Random State:            42\n",
      "Use GroupKFold:          True\n",
      "Regression Metric:       neg_root_mean_squared_error\n",
      "Classification Metric:   f1_macro\n",
      "\n",
      "--- Feature Columns ---\n",
      "Numeric (7):        ['year', 'engine_hp', 'engine_cylinders', 'highway_mpg', 'city_mpg', 'popularity', 'number_of_doors']\n",
      "Categorical (8): ['make', 'model', 'engine_fuel_type', 'transmission_type', 'driven_wheels', 'market_category', 'vehicle_size', 'vehicle_style']\n",
      "\n",
      "--- Hyperparameter Search Settings ---\n",
      "SVR Iterations:          25\n",
      "SVR Max Iter:            25000\n",
      "SVR Cache Size:          2000 MB\n",
      "\n",
      "Core configuration loaded successfully.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"Data/data.csv\"\n",
    "BEST_REGRESSOR_PATH = \"models/best_regressor.joblib\"\n",
    "BEST_CLASSIFIER_PATH = \"models/best_classifier.joblib\"\n",
    "LEADERBOARD_PATH = \"reports/leaderboards.json\"\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TARGET = \"msrp\"\n",
    "TARGET_CLS = \"performance_category\"\n",
    "\n",
    "CV = StratifiedKFold(5, shuffle=True, random_state=RANDOM_STATE)\n",
    "CV5 = KFold(5, shuffle=True, random_state=RANDOM_STATE)\n",
    "GKF = GroupKFold(n_splits=5)\n",
    "USE_GROUP_CV = True\n",
    "\n",
    "SCORE_REG = \"neg_root_mean_squared_error\"\n",
    "SCORE_CLA = \"f1_macro\"\n",
    "CACHE_SIZE = 2000\n",
    "MAX_ITER = 25000\n",
    "N_ITER = 25\n",
    "\n",
    "# Feature lists\n",
    "NUMERIC = [\"year\", \"engine_hp\", \"engine_cylinders\", \"highway_mpg\", \"city_mpg\", \"popularity\", \"number_of_doors\"]\n",
    "CATEGORICAL = [\"make\", \"model\", \"engine_fuel_type\", \"transmission_type\", \"driven_wheels\", \"market_category\", \"vehicle_size\", \"vehicle_style\"]\n",
    "\n",
    "# Hypertune lists\n",
    "ALPHA  = [1e-4,1e-3,1e-2,1e-1,0.5,1,10,50,100]\n",
    "COEF = 10**np.linspace(-3,3,101)\n",
    "EPSILON = np.linspace(0,0.1,11)\n",
    "DEGREE = [2,3,4,5]\n",
    "GAMMA = ['scale','auto']\n",
    "COEF0 = [0.0,1.0,5.0]\n",
    "N_NEIGHBORS = [1,2,3,5,7,9,11,15,20,25,30,40,50,75,100]\n",
    "WEIGHTS = [\"uniform\",\"distance\"]\n",
    "LOGREG_PENALTY = [\"l2\"]\n",
    "LOGREG_C = [0.01,0.1,0.5,1,2,5,10]\n",
    "LOGREG_SOLVER = [\"lbfgs\",\"saga\"]\n",
    "LDA_SOLVER = [\"svd\",\"lsqr\",\"eigen\"]\n",
    "QDA_REG_PARAM = np.linspace(0.05, 0.9, 10)\n",
    "\n",
    "print(f\"DATA_PATH:               {DATA_PATH}\")\n",
    "print(f\"BEST_REGRESSOR_PATH:     {BEST_REGRESSOR_PATH}\")\n",
    "print(f\"BEST_CLASSIFIER_PATH:    {BEST_CLASSIFIER_PATH}\")\n",
    "print(f\"LEADERBOARD_PATH:        {LEADERBOARD_PATH}\")\n",
    "print(f\"\\nRandom State:            {RANDOM_STATE}\")\n",
    "print(f\"Use GroupKFold:          {USE_GROUP_CV}\")\n",
    "print(f\"Regression Metric:       {SCORE_REG}\")\n",
    "print(f\"Classification Metric:   {SCORE_CLA}\")\n",
    "print(\"\\n--- Feature Columns ---\")\n",
    "print(f\"Numeric ({len(NUMERIC)}):        {NUMERIC}\")\n",
    "print(f\"Categorical ({len(CATEGORICAL)}): {CATEGORICAL}\")\n",
    "print(\"\\n--- Hyperparameter Search Settings ---\")\n",
    "print(f\"SVR Iterations:          {N_ITER}\")\n",
    "print(f\"SVR Max Iter:            {MAX_ITER}\")\n",
    "print(f\"SVR Cache Size:          {CACHE_SIZE} MB\")\n",
    "\n",
    "print(\"\\nCore configuration loaded successfully.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01aa15df",
   "metadata": {},
   "source": [
    "# **PREPROCESS AND SPLIT DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5deac1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Loaded data: 11726 rows\n",
      "[OK] Required columns present: All good\n",
      "[OK] Regression target OK: 'msrp'\n",
      "[OK] Classification target OK: 'performance_category'\n",
      "[OK] Feature ready: age\n",
      "[OK] Feature ready: hp_per_cyl\n",
      "[OK] Feature ready: drivetrain_simple\n",
      "[OK] Regression features after leakage drop: 12 columns\n",
      "[OK] Classification features (HP leakage removed): 24 columns\n",
      "[OK] Regression split: (8208, 12) train | (3518, 12) test\n",
      "[OK] Classification split: (8208, 24) train | (3518, 24) test\n"
     ]
    }
   ],
   "source": [
    "car_data = pd.read_csv(DATA_PATH)\n",
    "car_data.columns = [c.strip().lower().replace(\" \",\"_\").replace(\"-\",\"_\") for c in car_data.columns]\n",
    "\n",
    "# Needed columns check\n",
    "needed = set(NUMERIC + CATEGORICAL + [TARGET])\n",
    "missing = [col for col in needed if col not in car_data.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "# Numeric coercion\n",
    "for col in NUMERIC + [TARGET]:\n",
    "    car_data[col] = pd.to_numeric(car_data[col], errors=\"coerce\")\n",
    "\n",
    "# Create performance_category from engine_hp\n",
    "hp = pd.to_numeric(car_data[\"engine_hp\"], errors=\"coerce\")\n",
    "mask = hp.notna()\n",
    "car_data.loc[mask, TARGET_CLS] = pd.qcut(hp[mask], q=3, labels=[\"Economy\",\"Mid\",\"Sport\"])\n",
    "car_data = car_data.dropna(subset=[TARGET_CLS])\n",
    "\n",
    "# Drop rows missing target\n",
    "car_data = car_data.dropna(subset=[TARGET])\n",
    "\n",
    "# Fill categoricals\n",
    "for col in CATEGORICAL:\n",
    "    car_data[col] = car_data[col].fillna(\"\")\n",
    "\n",
    "# Cast some ints\n",
    "for col in [\"year\",\"engine_cylinders\",\"number_of_doors\",\"popularity\"]:\n",
    "    if col in car_data.columns:\n",
    "        car_data[col] = pd.to_numeric(car_data[col], errors=\"coerce\").round().astype(\"Int64\")\n",
    "\n",
    "# Feature engineering\n",
    "car_data[\"combined_mpg\"] = (car_data[\"city_mpg\"] + car_data[\"highway_mpg\"]) / 2.0\n",
    "den = car_data[\"engine_cylinders\"].replace({0:np.nan})\n",
    "car_data[\"hp_per_cyl\"] = (car_data[\"engine_hp\"] / den).replace([np.inf,-np.inf], np.nan)\n",
    "car_data[\"drivetrain_simple\"] = car_data[\"driven_wheels\"].astype(str).str.extract(r\"(front|rear|all)\", expand=False).fillna(car_data[\"driven_wheels\"].astype(str))\n",
    "\n",
    "# Trim top 1% msrp\n",
    "upper_limit = car_data[\"msrp\"].quantile(0.99)\n",
    "car_data = car_data[car_data[\"msrp\"] <= upper_limit]\n",
    "\n",
    "# Log target\n",
    "car_data[\"log_msrp\"] = np.log1p(car_data[\"msrp\"])\n",
    "\n",
    "# Extra features\n",
    "car_data[\"hp_x_year\"] = car_data[\"engine_hp\"] * car_data[\"year\"]\n",
    "car_data[\"mpg_ratio\"] = car_data[\"highway_mpg\"] / (car_data[\"city_mpg\"] + 1)\n",
    "car_data[\"hp_per_door\"] = car_data[\"engine_hp\"] / (car_data[\"number_of_doors\"] + 1)\n",
    "car_data[\"is_luxury\"] = car_data[\"market_category\"].str.contains(\"Luxury\", case=False, na=False).astype(int)\n",
    "car_data[\"is_suv\"] = car_data[\"vehicle_style\"].str.contains(\"SUV\", case=False, na=False).astype(int)\n",
    "car_data[\"is_performance\"] = car_data[\"market_category\"].str.contains(\"Performance\", case=False, na=False).astype(int)\n",
    "top_makes = car_data[\"make\"].value_counts().nlargest(15).index\n",
    "car_data[\"make_grouped\"] = car_data[\"make\"].where(car_data[\"make\"].isin(top_makes), \"Other\")\n",
    "\n",
    "# year -> age\n",
    "car_data[\"age\"] = car_data[\"year\"].max() - car_data[\"year\"]\n",
    "\n",
    "# Final cleaned lists\n",
    "NUMERIC_CLEAN = [\"age\",\"engine_hp\",\"engine_cylinders\",\"highway_mpg\",\"city_mpg\",\"number_of_doors\"]\n",
    "CATEGORICAL_SMALL = [\"engine_fuel_type\",\"transmission_type\",\"driven_wheels\"]\n",
    "CATEGORICAL_TE = [\"make\"]\n",
    "\n",
    "# Split datasets properly: regression removes performance_category, classification keeps it\n",
    "X_all = car_data.drop(columns=[\"msrp\",\"log_msrp\"])\n",
    "y_reg_full = car_data[\"log_msrp\"]\n",
    "y_cls_full = car_data[TARGET_CLS]\n",
    "\n",
    "# For regression X, drop derived columns and classification target to prevent leakage\n",
    "DROP_FOR_REG = [\"performance_category\",\"model\",\"model_grouped\",\"make_grouped\",\"market_category\",\"vehicle_style\",\"vehicle_size\",\n",
    "                \"is_performance\",\"is_luxury\",\"is_suv\",\"hp_x_year\",\"hp_per_cyl\",\"hp_per_door\",\"combined_mpg\",\"mpg_ratio\",\"popularity\"]\n",
    "X_reg = X_all.drop(columns=[c for c in DROP_FOR_REG if c in X_all.columns], errors=\"ignore\")\n",
    "\n",
    "# For classification, keep performance_category, but remove engine_hp leakage\n",
    "X_cls = X_all.copy()\n",
    "\n",
    "# Train/test splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reg, y_reg_full, test_size=0.3, random_state=RANDOM_STATE)\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(X_cls, y_cls_full, test_size=0.3, stratify=y_cls_full, random_state=RANDOM_STATE)\n",
    "\n",
    "# For classification, drop horsepower-based columns to avoid leakage\n",
    "leakage_features = [\"engine_hp\",\"hp_per_cyl\",\"hp_x_year\"]\n",
    "Xc_train = Xc_train.drop(columns=[c for c in leakage_features if c in Xc_train.columns], errors=\"ignore\")\n",
    "Xc_test = Xc_test.drop(columns=[c for c in leakage_features if c in Xc_test.columns], errors=\"ignore\")\n",
    "\n",
    "NUMERIC_CLS = [c for c in NUMERIC_CLEAN if c in Xc_train.columns and c not in leakage_features]\n",
    "CATEGORICAL_CLS = [c for c in CATEGORICAL if c in Xc_train.columns]\n",
    "\n",
    "print(f\"[OK] Loaded data: {len(car_data)} rows\")\n",
    "print(f\"[OK] Required columns present: {missing if missing else 'All good'}\")\n",
    "print(f\"[OK] Regression target OK: '{TARGET}'\")\n",
    "print(f\"[OK] Classification target OK: '{TARGET_CLS}'\")\n",
    "critical_features = [\"age\", \"hp_per_cyl\", \"drivetrain_simple\"]\n",
    "for feat in critical_features: print(f\"[OK] Feature ready: {feat}\" if feat in car_data.columns else f\"[FAIL] Missing: {feat}\")\n",
    "print(f\"[OK] Regression features after leakage drop: {X_train.shape[1]} columns\")\n",
    "print(f\"[OK] Classification features (HP leakage removed): {Xc_train.shape[1]} columns\")\n",
    "print(f\"[OK] Regression split: {X_train.shape} train | {X_test.shape} test\")\n",
    "print(f\"[OK] Classification split: {Xc_train.shape} train | {Xc_test.shape} test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b918050e",
   "metadata": {},
   "source": [
    "# **PIPELINE BUILT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97f52e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Regression preprocessor ready: 6 numeric, 3 categorical\n",
      " Classification preprocessor ready: 5 numeric, 8 categorical\n",
      " ToDenseTransformer loaded: True\n",
      " TorchMLPRegressor: Enabled\n",
      " TorchMLPClassifier: Enabled\n"
     ]
    }
   ],
   "source": [
    "class ToDenseTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X): return X.toarray() if hasattr(X, \"toarray\") else X\n",
    "\n",
    "numeric_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")), \n",
    "    (\"scaler\", RobustScaler())])\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), \n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "\n",
    "preprocessor_reg = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, NUMERIC_CLEAN), \n",
    "    (\"cat\", categorical_transformer, CATEGORICAL_SMALL)], remainder=\"drop\")\n",
    "preprocessor_cls = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, NUMERIC_CLS), \n",
    "    (\"cat\", categorical_transformer, CATEGORICAL_CLS)], remainder=\"drop\")\n",
    "\n",
    "if USE_TORCH:\n",
    "    class TorchMLPRegressor(BaseEstimator):\n",
    "        def __init__(self, hidden_layer_sizes=(64,64), lr=1e-3, batch_size=128, epochs=50, device=None, random_state=RANDOM_STATE):\n",
    "            self.hidden_layer_sizes = hidden_layer_sizes\n",
    "            self.lr = lr\n",
    "            self.batch_size = batch_size\n",
    "            self.epochs = epochs\n",
    "            self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            self.random_state = random_state\n",
    "            self.model_ = None\n",
    "\n",
    "        def _build_model(self, input_dim):\n",
    "            layers = []\n",
    "            in_dim = input_dim\n",
    "            for h in self.hidden_layer_sizes:\n",
    "                layers.append(nn.Linear(in_dim, h))\n",
    "                layers.append(nn.ReLU())\n",
    "                in_dim = h\n",
    "            layers.append(nn.Linear(in_dim, 1))\n",
    "            return nn.Sequential(*layers).to(self.device)\n",
    "\n",
    "        def fit(self, X, y):\n",
    "            torch.manual_seed(self.random_state)\n",
    "            if isinstance(X, np.ndarray):\n",
    "                X_np = X.astype(np.float32)\n",
    "            else:\n",
    "                X_np = X.values.astype(np.float32)\n",
    "            y_np = y.values.astype(np.float32).reshape(-1,1)\n",
    "            dataset = TensorDataset(torch.from_numpy(X_np), torch.from_numpy(y_np))\n",
    "            loader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "            self.model_ = self._build_model(X_np.shape[1])\n",
    "            opt = optim.Adam(self.model_.parameters(), lr=self.lr)\n",
    "            loss_fn = nn.MSELoss()\n",
    "            self.model_.train()\n",
    "            for epoch in range(self.epochs):\n",
    "                epoch_loss = 0.0\n",
    "                for xb, yb in loader:\n",
    "                    xb, yb = xb.to(self.device), yb.to(self.device)\n",
    "                    opt.zero_grad()\n",
    "                    out = self.model_(xb)\n",
    "                    loss = loss_fn(out, yb)\n",
    "                    loss.backward()\n",
    "                    opt.step()\n",
    "                    epoch_loss += float(loss.item()) * xb.size(0)\n",
    "            return self\n",
    "\n",
    "        def predict(self, X):\n",
    "            if isinstance(X, np.ndarray):\n",
    "                X_np = X.astype(np.float32)\n",
    "            else:\n",
    "                X_np = X.values.astype(np.float32)\n",
    "            self.model_.eval()\n",
    "            with torch.no_grad():\n",
    "                xb = torch.from_numpy(X_np).to(self.device)\n",
    "                out = self.model_(xb).cpu().numpy().reshape(-1)\n",
    "            return out\n",
    "\n",
    "    class TorchMLPClassifier(BaseEstimator):\n",
    "        def __init__(self, hidden_layer_sizes=(64,64), lr=1e-3, batch_size=128, epochs=50, device=None, random_state=RANDOM_STATE):\n",
    "            self.hidden_layer_sizes = hidden_layer_sizes\n",
    "            self.lr = lr\n",
    "            self.batch_size = batch_size\n",
    "            self.epochs = epochs\n",
    "            self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            self.random_state = random_state\n",
    "            self.model_ = None\n",
    "            self.classes_ = None\n",
    "\n",
    "        def _build_model(self, input_dim, n_classes):\n",
    "            layers = []\n",
    "            in_dim = input_dim\n",
    "            for h in self.hidden_layer_sizes:\n",
    "                layers.append(nn.Linear(in_dim, h))\n",
    "                layers.append(nn.ReLU())\n",
    "                in_dim = h\n",
    "            layers.append(nn.Linear(in_dim, n_classes))\n",
    "            return nn.Sequential(*layers).to(self.device)\n",
    "\n",
    "        def fit(self, X, y):\n",
    "            torch.manual_seed(self.random_state)\n",
    "            if isinstance(X, np.ndarray):\n",
    "                X_np = X.astype(np.float32)\n",
    "            else:\n",
    "                X_np = X.values.astype(np.float32)\n",
    "            y_np_raw = y.values\n",
    "            classes, y_np = np.unique(y_np_raw, return_inverse=True)\n",
    "            self.classes_ = classes\n",
    "            dataset = TensorDataset(torch.from_numpy(X_np), torch.from_numpy(y_np.astype(np.int64)))\n",
    "            loader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "            self.model_ = self._build_model(X_np.shape[1], len(classes))\n",
    "            opt = optim.Adam(self.model_.parameters(), lr=self.lr)\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            self.model_.train()\n",
    "            for epoch in range(self.epochs):\n",
    "                for xb, yb in loader:\n",
    "                    xb, yb = xb.to(self.device), yb.to(self.device)\n",
    "                    opt.zero_grad()\n",
    "                    out = self.model_(xb)\n",
    "                    loss = loss_fn(out, yb)\n",
    "                    loss.backward()\n",
    "                    opt.step()\n",
    "            return self\n",
    "\n",
    "        def predict(self, X):\n",
    "            if isinstance(X, np.ndarray):\n",
    "                X_np = X.astype(np.float32)\n",
    "            else:\n",
    "                X_np = X.values.astype(np.float32)\n",
    "            self.model_.eval()\n",
    "            with torch.no_grad():\n",
    "                xb = torch.from_numpy(X_np).to(self.device)\n",
    "                logits = self.model_(xb).cpu().numpy()\n",
    "                preds = np.argmax(logits, axis=1)\n",
    "            return self.classes_[preds]\n",
    "\n",
    "else:\n",
    "    TorchMLPRegressor = None\n",
    "    TorchMLPClassifier = None\n",
    "\n",
    "def sanitize_for_json(params):\n",
    "    clean = {}\n",
    "    for k, v in params.items():\n",
    "        if isinstance(v, (int, float, str, bool, list, dict)):\n",
    "            clean[k] = v\n",
    "        else:\n",
    "            clean[k] = str(v)\n",
    "    return clean\n",
    "\n",
    "print(f\" Regression preprocessor ready: {len(NUMERIC_CLEAN)} numeric, {len(CATEGORICAL_SMALL)} categorical\")\n",
    "print(f\" Classification preprocessor ready: {len(NUMERIC_CLS)} numeric, {len(CATEGORICAL_CLS)} categorical\")\n",
    "print(f\" ToDenseTransformer loaded: {callable(getattr(ToDenseTransformer, 'transform', None))}\")\n",
    "print(f\" TorchMLPRegressor: {'Enabled' if TorchMLPRegressor else 'Disabled'}\")\n",
    "print(f\" TorchMLPClassifier: {'Enabled' if TorchMLPClassifier else 'Disabled'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65867c21",
   "metadata": {},
   "source": [
    "# **SELECTING AND TRAINING MODEL WITH BEST PARAMS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e794d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GroupKFold for regression.\n",
      "\n",
      "No saved regressor found — training regression models...\n",
      "\n",
      "================= REGRESSION RESULTS =================\n",
      "\n",
      "\n",
      " Training TraditionalFamily ...\n",
      "   TraditionalFamily Results:\n",
      "   Best Params: {'preprocessor__num__imputer': SimpleImputer(strategy='median'), 'preprocessor__num__scaler': MinMaxScaler(), 'regressor': KNeighborsRegressor(), 'regressor__n_neighbors': 5, 'regressor__weights': 'distance'}\n",
      "   Regressor: KNeighborsRegressor\n",
      "   Kernel: N/A\n",
      "   RMSE: 9236.70\n",
      "   MAE:  4376.55\n",
      "   R²:   0.929\n",
      "   Time: 53.9s\n",
      "\n",
      " Training SVR-Bayesian ...\n",
      "   SVR-Bayesian Results:\n",
      "   Best Params: OrderedDict({'regressor': SVR(cache_size=2000, max_iter=25000), 'regressor__C': 23.9883291901949, 'regressor__coef0': 0.0, 'regressor__degree': 3, 'regressor__epsilon': 0.09, 'regressor__gamma': 'scale'})\n",
      "   Regressor: SVR\n",
      "   Kernel: rbf\n",
      "   RMSE: 9442.48\n",
      "   MAE:  5063.62\n",
      "   R²:   0.925\n",
      "   Time: 352.0s\n",
      "\n",
      "===== REGRESSION MODEL COMPARISON =====\n",
      "Model                | Regressor            | Kernel     |       RMSE |        MAE |     R²\n",
      "--------------------------------------------------------------------------------\n",
      "TraditionalFamily    | KNeighborsRegressor  | N/A        |    9236.70 |    4376.55 |  0.929\n",
      "SVR-Bayesian         | SVR                  | rbf        |    9442.48 |    5063.62 |  0.925\n",
      "\n",
      "Best Regressor: TraditionalFamily (KNeighborsRegressor) with R²=0.93 saved to models/best_regressor.joblib\n",
      "\n",
      "No saved classifier found — training classification models...\n",
      "\n",
      "================= CLASSIFICATION RESULTS =================\n",
      "\n",
      "\n",
      " Training GridSearch_LogReg_KNN ...\n",
      "   GridSearch_LogReg_KNN (KNeighborsClassifier) Results:\n",
      "   Best Params: {'clf': KNeighborsClassifier(), 'clf__n_neighbors': 3, 'clf__weights': 'distance', 'preprocessor__num__imputer': SimpleImputer(strategy='median'), 'preprocessor__num__scaler': StandardScaler()}\n",
      "   Accuracy: 0.97 | F1_macro: 0.97 | Kernel: N/A\n",
      "\n",
      "   Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Economy      0.982     0.983     0.982      1214\n",
      "         Mid      0.958     0.964     0.961      1162\n",
      "       Sport      0.982     0.975     0.979      1142\n",
      "\n",
      "    accuracy                          0.974      3518\n",
      "   macro avg      0.974     0.974     0.974      3518\n",
      "weighted avg      0.974     0.974     0.974      3518\n",
      "\n",
      "   Time: 140.3s\n",
      "\n",
      " Training GridSearch_LDA_QDA_NB ...\n",
      "   GridSearch_LDA_QDA_NB (LinearDiscriminantAnalysis) Results:\n",
      "   Best Params: {'clf': LinearDiscriminantAnalysis(), 'clf__solver': 'lsqr'}\n",
      "   Accuracy: 0.94 | F1_macro: 0.94 | Kernel: N/A\n",
      "\n",
      "   Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Economy      0.947     0.951     0.949      1214\n",
      "         Mid      0.896     0.911     0.904      1162\n",
      "       Sport      0.965     0.944     0.954      1142\n",
      "\n",
      "    accuracy                          0.936      3518\n",
      "   macro avg      0.936     0.936     0.936      3518\n",
      "weighted avg      0.936     0.936     0.936      3518\n",
      "\n",
      "   Time: 158.0s\n",
      "\n",
      " Training BayesSearch_SVM ...\n",
      "   BayesSearch_SVM (SVC) Results:\n",
      "   Best Params: OrderedDict({'clf': SVC(cache_size=2000, max_iter=25000, probability=True), 'clf__C': 331.1733327754671, 'clf__coef0': 2.4823335179835837, 'clf__degree': 5, 'clf__gamma': 'scale'})\n",
      "   Accuracy: 0.98 | F1_macro: 0.98 | Kernel: rbf\n",
      "\n",
      "   Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Economy      0.985     0.987     0.986      1214\n",
      "         Mid      0.970     0.976     0.973      1162\n",
      "       Sport      0.991     0.983     0.987      1142\n",
      "\n",
      "    accuracy                          0.982      3518\n",
      "   macro avg      0.982     0.982     0.982      3518\n",
      "weighted avg      0.982     0.982     0.982      3518\n",
      "\n",
      "   Time: 399.7s\n",
      "\n",
      "===== CLASSIFICATION MODEL COMPARISON =====\n",
      "Model                     | Classifier           | Kernel     |   Accuracy |   F1_macro\n",
      "--------------------------------------------------------------------------------\n",
      "GridSearch_LogReg_KNN     | KNeighborsClassifier | N/A        |       0.97 |       0.97\n",
      "GridSearch_LDA_QDA_NB     | LinearDiscriminantAnalysis | N/A        |       0.94 |       0.94\n",
      "BayesSearch_SVM           | SVC                  | rbf        |       0.98 |       0.98\n",
      "\n",
      "Best Classifier: BayesSearch_SVM (SVC) with Accuracy=0.98 saved to models/best_classifier.joblib\n",
      "\n",
      "Leaderboard saved at: reports/leaderboards.json\n",
      "\n",
      "Best models ready for use:\n",
      "   Regressor: models/best_regressor.joblib\n",
      "   Classifier: models/best_classifier.joblib\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if USE_GROUP_CV and \"make\" in X_train.columns:\n",
    "    groups = X_train[\"make\"]\n",
    "    CV_REG = list(GKF.split(X_train, y_train, groups=groups))\n",
    "    print(\"Using GroupKFold for regression.\")\n",
    "else:\n",
    "    CV_REG = CV5\n",
    "    print(\"Using standard KFold for regression.\")\n",
    "\n",
    "regressors = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"ElasticNet\": ElasticNet(),\n",
    "    \"KNeighborsRegressor\": KNeighborsRegressor()\n",
    "}\n",
    "if USE_TORCH and TORCH_CUDA:\n",
    "    regressors[\"TorchMLPRegressor\"] = TorchMLPRegressor(hidden_layer_sizes=(128,64), lr=1e-3, batch_size=128, epochs=60)\n",
    "elif USE_TORCH and not TORCH_CUDA:\n",
    "    regressors[\"TorchMLPRegressor\"] = TorchMLPRegressor(hidden_layer_sizes=(128,64), lr=1e-3, batch_size=64, epochs=60, device=\"cpu\")\n",
    "else:\n",
    "    regressors[\"SKMLPRegressor\"] = SKMLPRegressor(hidden_layer_sizes=(128,64), max_iter=200, random_state=RANDOM_STATE)\n",
    "\n",
    "classifiers = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=5000, random_state=RANDOM_STATE),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "    \"LinearDiscriminantAnalysis\": LinearDiscriminantAnalysis(),\n",
    "    \"QuadraticDiscriminantAnalysis\": QuadraticDiscriminantAnalysis(),\n",
    "    \"GaussianNB\": GaussianNB()\n",
    "}\n",
    "# MLP classifier\n",
    "if USE_TORCH and TORCH_CUDA:\n",
    "    classifiers[\"TorchMLPClassifier\"] = TorchMLPClassifier(hidden_layer_sizes=(128,64), lr=1e-3, batch_size=128, epochs=60)\n",
    "elif USE_TORCH and not TORCH_CUDA:\n",
    "    classifiers[\"TorchMLPClassifier\"] = TorchMLPClassifier(hidden_layer_sizes=(128,64), lr=1e-3, batch_size=64, epochs=60, device=\"cpu\")\n",
    "else:\n",
    "    classifiers[\"SKMLPClassifier\"] = SKMLPClassifier(hidden_layer_sizes=(128,64), max_iter=200, random_state=RANDOM_STATE)\n",
    "\n",
    "GRID_PARAM = [\n",
    "    {\n",
    "        \"preprocessor__num__imputer\": [SimpleImputer(strategy=\"median\"), KNNImputer(n_neighbors=5)],\n",
    "        \"preprocessor__num__scaler\": [StandardScaler(), RobustScaler(), PowerTransformer()],\n",
    "        \"regressor\": [Ridge(), Lasso(), ElasticNet()],\n",
    "        \"regressor__alpha\": ALPHA\n",
    "    },\n",
    "    {\n",
    "        \"preprocessor__num__imputer\": [KNNImputer(n_neighbors=5), SimpleImputer(strategy=\"median\")],\n",
    "        \"preprocessor__num__scaler\": [StandardScaler(), MinMaxScaler(), RobustScaler()],\n",
    "        \"regressor\": [LinearRegression()]\n",
    "    },\n",
    "    {\n",
    "        \"preprocessor__num__imputer\": [KNNImputer(n_neighbors=5), SimpleImputer(strategy=\"median\")],\n",
    "        \"preprocessor__num__scaler\": [MinMaxScaler(), RobustScaler()],\n",
    "        \"regressor\": [KNeighborsRegressor()],\n",
    "        \"regressor__n_neighbors\": N_NEIGHBORS,\n",
    "        \"regressor__weights\": WEIGHTS\n",
    "    }\n",
    "]\n",
    "\n",
    "BAYES_PARAM_SPACE = {\n",
    "    \"regressor\": Categorical([\n",
    "        SVR(kernel=\"linear\", max_iter=MAX_ITER, cache_size=CACHE_SIZE),\n",
    "        SVR(kernel=\"poly\", max_iter=MAX_ITER, cache_size=CACHE_SIZE),\n",
    "        SVR(kernel=\"rbf\", max_iter=MAX_ITER, cache_size=CACHE_SIZE),\n",
    "    ]),\n",
    "    \"regressor__C\": COEF,\n",
    "    \"regressor__epsilon\": EPSILON,\n",
    "    \"regressor__gamma\": GAMMA,\n",
    "    \"regressor__degree\": DEGREE,\n",
    "    \"regressor__coef0\": COEF0\n",
    "}\n",
    "\n",
    "GRID_PARAM_CLS = [\n",
    "    {\n",
    "        \"preprocessor__num__imputer\": [SimpleImputer(strategy=\"median\")],\n",
    "        \"preprocessor__num__scaler\": [StandardScaler(), RobustScaler()],\n",
    "        \"clf\": [LogisticRegression(max_iter=5000, random_state=RANDOM_STATE)],\n",
    "        \"clf__C\": LOGREG_C,\n",
    "        \"clf__solver\": LOGREG_SOLVER,\n",
    "        \"clf__penalty\": LOGREG_PENALTY\n",
    "    },\n",
    "    {\n",
    "        \"preprocessor__num__imputer\": [SimpleImputer(strategy=\"median\")],\n",
    "        \"preprocessor__num__scaler\": [StandardScaler()],\n",
    "        \"clf\": [KNeighborsClassifier()],\n",
    "        \"clf__n_neighbors\": [3,5,7,11],\n",
    "        \"clf__weights\": [\"uniform\",\"distance\"]\n",
    "    },\n",
    "]\n",
    "\n",
    "GRID_PARAM_CLS_2 = [\n",
    "    {\"clf\": [LinearDiscriminantAnalysis()], \"clf__solver\": LDA_SOLVER},\n",
    "    {\"clf\": [QuadraticDiscriminantAnalysis()], \"clf__reg_param\": QDA_REG_PARAM},\n",
    "    {\"clf\": [GaussianNB()]},\n",
    "]\n",
    "\n",
    "BAYES_PARAM_SPACE_CLS = {\n",
    "    \"clf\": Categorical([\n",
    "        SVC(kernel=\"linear\", probability=True, max_iter=MAX_ITER, cache_size=CACHE_SIZE),\n",
    "        SVC(kernel=\"rbf\", probability=True, max_iter=MAX_ITER, cache_size=CACHE_SIZE),\n",
    "        SVC(kernel=\"poly\", probability=True, max_iter=MAX_ITER, cache_size=CACHE_SIZE)\n",
    "    ]),\n",
    "    \"clf__C\": Real(1e-3, 1e3, prior=\"log-uniform\"),\n",
    "    \"clf__gamma\": Categorical([\"scale\",\"auto\"]),\n",
    "    \"clf__degree\": Integer(2,5),\n",
    "    \"clf__coef0\": Real(0.0,5.0)\n",
    "}\n",
    "\n",
    "model_reg = Pipeline([(\"preprocessor\", preprocessor_reg), (\"regressor\", Ridge())])\n",
    "model_cls = Pipeline([(\"preprocessor\", preprocessor_cls), (\"clf\", LogisticRegression(max_iter=5000, random_state=RANDOM_STATE))])\n",
    "model_cls_2 = Pipeline([(\"preprocessor\", preprocessor_cls), (\"to_dense\", ToDenseTransformer()), (\"clf\", LinearDiscriminantAnalysis())])\n",
    "\n",
    "models_reg = {\n",
    "    \"TraditionalFamily\": GridSearchCV(\n",
    "        estimator=model_reg, param_grid=GRID_PARAM,\n",
    "        cv=CV5, scoring=SCORE_REG, n_jobs=-1, refit=True\n",
    "    ),\n",
    "    \"SVR-Bayesian\": BayesSearchCV(\n",
    "        estimator=model_reg, search_spaces=BAYES_PARAM_SPACE,\n",
    "        n_iter=N_ITER, cv=CV5, n_jobs=-1, scoring=SCORE_REG,\n",
    "        random_state=RANDOM_STATE, refit=True\n",
    "    )\n",
    "}\n",
    "\n",
    "models_cls = {\n",
    "    \"GridSearch_LogReg_KNN\": GridSearchCV(\n",
    "        estimator=model_cls, param_grid=GRID_PARAM_CLS,\n",
    "        cv=CV5, scoring=SCORE_CLA, n_jobs=-1\n",
    "    ),\n",
    "    \"GridSearch_LDA_QDA_NB\": GridSearchCV(\n",
    "        estimator=model_cls_2, param_grid=GRID_PARAM_CLS_2,\n",
    "        cv=CV5, scoring=SCORE_CLA, n_jobs=-1\n",
    "    ),\n",
    "    \"BayesSearch_SVM\": BayesSearchCV(\n",
    "        estimator=model_cls, search_spaces=BAYES_PARAM_SPACE_CLS,\n",
    "        n_iter=N_ITER, cv=CV, n_jobs=-1, scoring=SCORE_CLA,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "}\n",
    "\n",
    "best_regressor = None\n",
    "best_classifier = None\n",
    "results_reg, results_cls = {}, {}\n",
    "\n",
    "os.makedirs(os.path.dirname(BEST_REGRESSOR_PATH), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(BEST_CLASSIFIER_PATH), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(LEADERBOARD_PATH), exist_ok=True)\n",
    "\n",
    "def safe_load_model(path):\n",
    "    try:\n",
    "        model = joblib.load(path)\n",
    "        meta = {}\n",
    "        try:\n",
    "            if hasattr(model, \"named_steps\"):\n",
    "                if \"regressor\" in model.named_steps:\n",
    "                    meta[\"estimator_name\"] = model.named_steps[\"regressor\"].__class__.__name__\n",
    "                elif \"clf\" in model.named_steps:\n",
    "                    meta[\"estimator_name\"] = model.named_steps[\"clf\"].__class__.__name__\n",
    "        except Exception:\n",
    "            pass\n",
    "        return model, meta\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {path}: {e}\")\n",
    "        return None, {}\n",
    "\n",
    "if os.path.exists(BEST_REGRESSOR_PATH):\n",
    "    print(\"\\nFound existing best regressor — loading.\")\n",
    "    best_regressor = joblib.load(BEST_REGRESSOR_PATH)\n",
    "else:\n",
    "    print(\"\\nNo saved regressor found — training regression models...\\n\")\n",
    "    print(\"================= REGRESSION RESULTS =================\\n\")\n",
    "    for name, search in models_reg.items():\n",
    "        print(f\"\\n Training {name} ...\")\n",
    "        try:\n",
    "            t0 = time.time()\n",
    "            search.fit(X_train, y_train)\n",
    "            t1 = time.time()\n",
    "            best_model = search.best_estimator_\n",
    "            # Evaluate on original scale\n",
    "            y_pred = np.expm1(best_model.predict(X_test))\n",
    "            y_true = np.expm1(y_test)\n",
    "            rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "            mae = mean_absolute_error(y_true, y_pred)\n",
    "            r2 = r2_score(y_true, y_pred)\n",
    "            reg_name = best_model.named_steps[\"regressor\"].__class__.__name__\n",
    "            kernel = getattr(best_model.named_steps[\"regressor\"], \"kernel\", \"N/A\")\n",
    "            print(f\"   {name} Results:\")\n",
    "            print(f\"   Best Params: {search.best_params_}\")\n",
    "            print(f\"   Regressor: {reg_name}\")\n",
    "            print(f\"   Kernel: {kernel}\")\n",
    "            print(f\"   RMSE: {rmse:.2f}\")\n",
    "            print(f\"   MAE:  {mae:.2f}\")\n",
    "            print(f\"   R²:   {r2:.3f}\")\n",
    "            print(f\"   Time: {t1-t0:.1f}s\")\n",
    "            results_reg[name] = {\"Regressor\": reg_name, \"RMSE\": rmse, \"MAE\": mae, \"R2\": r2, \"Kernel\": kernel, \"Best_Params\": sanitize_for_json(search.best_params_)}\n",
    "        except Exception as e:\n",
    "            print(f\" {name} failed due to: {e}\")\n",
    "\n",
    "    if results_reg:\n",
    "        print(\"\\n===== REGRESSION MODEL COMPARISON =====\")\n",
    "        print(f\"{'Model':<20} | {'Regressor':<20} | {'Kernel':<10} | {'RMSE':>10} | {'MAE':>10} | {'R²':>6}\")\n",
    "        print(\"-\" * 80)\n",
    "        for name, res in results_reg.items():\n",
    "            print(f\"{name:<20} | {res['Regressor']:<20} | {res['Kernel']:<10} | \"\n",
    "                  f\"{res['RMSE']:>10.2f} | {res['MAE']:>10.2f} | {res['R2']:>6.3f}\")\n",
    "    else:\n",
    "        print(\" No regression results available.\")\n",
    "        raise RuntimeError(\"Regression training failed — no valid models produced.\")\n",
    "\n",
    "    best_reg_name, best_reg = max(results_reg.items(), key=lambda x: x[1][\"R2\"])\n",
    "    best_regressor = models_reg[best_reg_name].best_estimator_\n",
    "    joblib.dump(best_regressor, BEST_REGRESSOR_PATH)\n",
    "    print(f\"\\nBest Regressor: {best_reg_name} ({best_reg['Regressor']}) with R²={best_reg['R2']:.2f} saved to {BEST_REGRESSOR_PATH}\")\n",
    "\n",
    "\n",
    "if os.path.exists(BEST_CLASSIFIER_PATH):\n",
    "    print(\"\\nFound existing best classifier — loading.\")\n",
    "    best_classifier = joblib.load(BEST_CLASSIFIER_PATH)\n",
    "else:\n",
    "    print(\"\\nNo saved classifier found — training classification models...\\n\")\n",
    "    print(\"================= CLASSIFICATION RESULTS =================\\n\")\n",
    "    for name, search in models_cls.items():\n",
    "        print(f\"\\n Training {name} ...\")\n",
    "        try:\n",
    "            t0 = time.time()\n",
    "            search.fit(Xc_train, yc_train)\n",
    "            t1 = time.time()\n",
    "            best_model = search.best_estimator_\n",
    "            clf_name = best_model.named_steps[\"clf\"].__class__.__name__\n",
    "            kernel = getattr(best_model.named_steps[\"clf\"], \"kernel\", \"N/A\")\n",
    "            y_pred = best_model.predict(Xc_test)\n",
    "            acc = accuracy_score(yc_test, y_pred)\n",
    "            f1 = f1_score(yc_test, y_pred, average=\"macro\")\n",
    "            print(f\"   {name} ({clf_name}) Results:\")\n",
    "            print(f\"   Best Params: {search.best_params_}\")\n",
    "            print(f\"   Accuracy: {acc:.2f} | F1_macro: {f1:.2f} | Kernel: {kernel}\")\n",
    "            print(\"\\n   Classification report:\")\n",
    "            print(classification_report(yc_test, y_pred, digits=3))\n",
    "            print(f\"   Time: {t1-t0:.1f}s\")\n",
    "            results_cls[name] = {\"Classifier\": clf_name, \"Accuracy\": acc, \"F1_macro\": f1, \"Kernel\": kernel, \"Best_Params\": sanitize_for_json(search.best_params_)\n",
    "}\n",
    "        except Exception as e:\n",
    "            print(f\" {name} failed due to: {e}\")\n",
    "\n",
    "    if results_cls:\n",
    "        print(\"\\n===== CLASSIFICATION MODEL COMPARISON =====\")\n",
    "        print(f\"{'Model':<25} | {'Classifier':<20} | {'Kernel':<10} | {'Accuracy':>10} | {'F1_macro':>10}\")\n",
    "        print(\"-\" * 80)\n",
    "        for name, res in results_cls.items():\n",
    "            print(f\"{name:<25} | {res['Classifier']:<20} | {res['Kernel']:<10} | \"\n",
    "                  f\"{res['Accuracy']:>10.2f} | {res['F1_macro']:>10.2f}\")\n",
    "    else:\n",
    "        print(\" No classification results available.\")\n",
    "        raise RuntimeError(\"Classification training failed — no valid models produced.\")\n",
    "\n",
    "    best_cls_name, best_cls = max(results_cls.items(), key=lambda x: x[1][\"Accuracy\"])\n",
    "    best_classifier = models_cls[best_cls_name].best_estimator_\n",
    "    joblib.dump(best_classifier, BEST_CLASSIFIER_PATH)\n",
    "    print(f\"\\nBest Classifier: {best_cls_name} ({best_cls['Classifier']}) with Accuracy={best_cls['Accuracy']:.2f} saved to {BEST_CLASSIFIER_PATH}\")\n",
    "\n",
    "# Leaderboard\n",
    "leaderboard = {\n",
    "    \"Best Regressor\": best_reg_name if 'best_reg_name' in globals() else \"Loaded existing model\",\n",
    "    \"Best Regressor Type\": best_reg.get(\"Regressor\") if 'best_reg' in globals() else \"Loaded existing model\",\n",
    "    \"Best Regressor R²\": best_reg.get(\"R2\") if 'best_reg' in globals() else \"N/A\",\n",
    "    \"Best Classifier\": best_cls_name if 'best_cls_name' in globals() else \"Loaded existing model\",\n",
    "    \"Best Classifier Type\": best_cls.get(\"Classifier\") if 'best_cls' in globals() else \"Loaded existing model\",\n",
    "    \"Best Classifier Accuracy\": best_cls.get(\"Accuracy\") if 'best_cls' in globals() else \"N/A\",\n",
    "    \"Regression Results\": results_reg,\n",
    "    \"Classification Results\": results_cls,\n",
    "    \"timestamp\": pd.Timestamp.now().isoformat()\n",
    "}\n",
    "\n",
    "with open(LEADERBOARD_PATH, \"w\") as f:\n",
    "    json.dump(leaderboard, f, indent=4)\n",
    "\n",
    "print(f\"\\nLeaderboard saved at: {LEADERBOARD_PATH}\")\n",
    "print(\"\\nBest models ready for use:\")\n",
    "print(f\"   Regressor: {BEST_REGRESSOR_PATH}\")\n",
    "print(f\"   Classifier: {BEST_CLASSIFIER_PATH}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9acaf81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script finished.\n",
      "Running GroupKFold baseline...\n",
      "GroupKFold baseline (neg RMSE) mean score: -0.4807\n",
      "\n",
      "Running permutation importance on best regressor...\n",
      "Top features by permutation importance (top 30):\n",
      "age                  0.971427\n",
      "engine_fuel_type     0.602611\n",
      "engine_hp            0.317449\n",
      "driven_wheels        0.315745\n",
      "transmission_type    0.313065\n",
      "engine_cylinders     0.225823\n",
      "number_of_doors      0.181892\n",
      "city_mpg             0.100115\n",
      "highway_mpg          0.069855\n",
      "year                -0.001125\n",
      "make                -0.001125\n",
      "drivetrain_simple   -0.001125\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "age                  0.971427\n",
       "engine_fuel_type     0.602611\n",
       "engine_hp            0.317449\n",
       "driven_wheels        0.315745\n",
       "transmission_type    0.313065\n",
       "engine_cylinders     0.225823\n",
       "number_of_doors      0.181892\n",
       "city_mpg             0.100115\n",
       "highway_mpg          0.069855\n",
       "year                -0.001125\n",
       "make                -0.001125\n",
       "drivetrain_simple   -0.001125\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_groupkfold_baseline(X_df, y_ser, group_col=\"make\"):\n",
    "    if group_col not in X_df.columns:\n",
    "        print(f\"Group column '{group_col}' not present in X; skipping GroupKFold baseline.\")\n",
    "        return None\n",
    "    gkf = GroupKFold(n_splits=5)\n",
    "    baseline = Pipeline([(\"preprocessor\", preprocessor_reg), (\"regressor\", Ridge(alpha=1.0))])\n",
    "    scores = cross_val_score(baseline, X_df, y_ser, cv=gkf.split(X_df, y_ser, groups=X_df[group_col]), scoring=SCORE_REG, n_jobs=-1)\n",
    "    print(f\"GroupKFold baseline (neg RMSE) mean score: {np.mean(scores):.4f}\")\n",
    "    return scores\n",
    "\n",
    "def compute_permutation_importance(model, X_df, y_ser, n_repeats=10, subset=500):\n",
    "    if model is None:\n",
    "        print(\"No fitted model provided for permutation importance.\")\n",
    "        return None\n",
    "    n = min(subset, len(X_df))\n",
    "    subX = X_df.sample(n, random_state=RANDOM_STATE)\n",
    "    suby = y_ser.loc[subX.index]\n",
    "    try:\n",
    "        res = permutation_importance(model, subX, suby, n_repeats=n_repeats, scoring=SCORE_REG, n_jobs=-1, random_state=RANDOM_STATE)\n",
    "        imp_df = pd.Series(res.importances_mean, index=subX.columns).sort_values(ascending=False)\n",
    "        print(\"Top features by permutation importance (top 30):\")\n",
    "        print(imp_df.head(30))\n",
    "        return imp_df\n",
    "    except Exception as e:\n",
    "        print(f\"Permutation importance failed: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"Script finished.\") \n",
    "print(\"Running GroupKFold baseline...\") \n",
    "run_groupkfold_baseline(X_train, y_train) \n",
    "print(\"\\nRunning permutation importance on best regressor...\") \n",
    "compute_permutation_importance(best_regressor, X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carPrediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
