{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd2b2aab",
   "metadata": {},
   "source": [
    "# **INSTALLS AND PACKAGES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9042916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import joblib\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OneHotEncoder, PowerTransformer, QuantileTransformer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f15935",
   "metadata": {},
   "source": [
    "# **SETTINGS AND PATH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a7b962a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................Configuration and Settings loaded successfully.\n",
      "Data path: Data/data.csv\n",
      "Random state: 42\n",
      "Target column: msrp\n",
      "Numeric features: 7 | Categorical features: 8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "DATA_PATH = \"Data/data.csv\"\n",
    "BEST_REGRESSOR_PATH = \"models/best_regressor.joblib\"\n",
    "BEST_CLASSIFIER_PATH = \"models/best_classifier.joblib\"\n",
    "LEADERBOARD_PATH = \"reports/leaderboards.json\"\n",
    "\n",
    "# General Settings\n",
    "RANDOM_STATE = 42\n",
    "TARGET = \"msrp\"\n",
    "TARGET_CLS = \"performance_category\"\n",
    "CV = StratifiedKFold(5, shuffle=True, random_state=RANDOM_STATE)\n",
    "CV5 = KFold(5, shuffle=True, random_state=RANDOM_STATE)\n",
    "SCORE_REG = \"neg_root_mean_squared_error\"\n",
    "SCORE_CLA = \"f1_macro\"\n",
    "CACHE_SIZE = 2000\n",
    "MAX_ITER = 25000\n",
    "N_ITER = 20\n",
    "\n",
    "\n",
    "NUMERIC = [\"year\", \"engine_hp\", \"engine_cylinders\", \"highway_mpg\", \"city_mpg\", \"popularity\", \"number_of_doors\"]\n",
    "CATEGORICAL = [\"make\", \"model\", \"engine_fuel_type\", \"transmission_type\", \"driven_wheels\",\"market_category\", \"vehicle_size\", \"vehicle_style\"]\n",
    "\n",
    "# LASSO/RIDGE settings\n",
    "ALPHA  =[1e-4, 1e-3, 1e-2, 1e-1, 0.5, 1, 10, 50, 100]\n",
    "\n",
    "# SVR settings\n",
    "COEF =10**np.linspace(-3, 3, 101)\n",
    "EPSILON = np.linspace(0, 0.1, 11)\n",
    "DEGREE = [2, 3, 4, 5]\n",
    "GAMMA = ['scale', 'auto']\n",
    "COEF0 = [0.0, 1.0, 5.0]\n",
    "# KNN settings\n",
    "N_NEIGHBORS = [1, 2, 3, 5, 7, 9, 11, 15, 20, 25, 30, 40, 50, 75, 100]\n",
    "WEIGHTS = [\"uniform\", \"distance\"]\n",
    "LEAF_SIZE = [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "METRIC = [\"euclidean\", \"manhattan\", \"minkowski\", \"chebyshev\", \"cosine\"]\n",
    "P = [1, 1.5, 2, 3]\n",
    "ALGORITHM = [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]\n",
    "\n",
    "# LogReg setting\n",
    "LOGREG_PENALTY = [\"l2\"]\n",
    "LOGREG_C = [0.01, 0.1, 0.5, 1, 2, 5, 10]\n",
    "LOGREG_SOLVER = [\"lbfgs\", \"saga\"]\n",
    "\n",
    "# LDA / QDA settings\n",
    "LDA_SOLVER = [\"svd\", \"lsqr\", \"eigen\"]\n",
    "QDA_REG_PARAM = np.linspace(0.05, 0.9, 10) #QDA_REG_PARAM = np.linspace(0.0, 0.5, 6)\n",
    "\n",
    "\n",
    "print(\"............................Configuration and Settings loaded successfully.\")\n",
    "print(f\"Data path: {DATA_PATH}\")\n",
    "print(f\"Random state: {RANDOM_STATE}\")\n",
    "print(f\"Target column: {TARGET}\")\n",
    "print(f\"Numeric features: {len(NUMERIC)} | Categorical features: {len(CATEGORICAL)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01aa15df",
   "metadata": {},
   "source": [
    "# **PREPROCESS AND SPLIT DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5deac1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data loaded successfully: 11,914 rows × 16 columns\n",
      "\n",
      "All required columns found (16 total).\n",
      "\n",
      "class Target  performance_category\n",
      "Economy    4045\n",
      "Sport      3926\n",
      "Mid        3874\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Target 'msrp' cleaned. Remaining rows: 11,845\n",
      "\n",
      "Feature engineering complete.\n",
      " new Features ['combined_mpg', 'drivetrain_simple', 'hp_per_cyl']\n",
      "\n",
      "After outlier removal: 11,726 rows\n",
      "\n",
      "Removed leakage features for classification: ['engine_hp', 'hp_per_cyl', 'hp_x_year']\n",
      "\n",
      "Classification training shape:  X_cls_train = (8208, 23), y_cls_train = (8208,)\n",
      "Classification testing shape:   X_cls_test  = (3518, 23),  y_cls_test  = (3518,)\n",
      "Regression training shape:      X_train     = (8208, 26), y_train     = (8208,)\n",
      "Regression testing shape:       X_test      = (3518, 26),  y_test      = (3518,)\n",
      "\n",
      "Data preparation completed successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "car_data = pd.read_csv(DATA_PATH)\n",
    "print (f\" Data loaded successfully: {car_data.shape[0]:,} rows × {car_data.shape[1]} columns\")\n",
    "\n",
    "car_data.columns = [c.strip().lower().replace(\" \",\"_\").replace(\"-\",\"_\") for c in car_data.columns] # Normalize column names\n",
    "\n",
    "rename_map = {\"engine_hp\": \"engine_hp\", \"engine_cylinders\": \"engine_cylinders\", \n",
    "              \"highway_mpg\": \"highway_mpg\", \"city_mpg\": \"city_mpg\", \"number_of_doors\": \"number_of_doors\", \n",
    "              \"driven_wheels\": \"driven_wheels\", \"engine_fuel_type\": \"engine_fuel_type\", \"transmission_type\": \"transmission_type\", \n",
    "              \"market_category\": \"market_category\", \"vehicle_size\": \"vehicle_size\", \"vehicle_style\": \"vehicle_style\", \n",
    "              \"popularity\": \"popularity\", \"msrp\": \"msrp\", \"make\": \"make\", \"model\": \"model\", \"year\": \"year\"}\n",
    "car_data = car_data.rename(columns=rename_map).copy()\n",
    "needed = set(NUMERIC + CATEGORICAL + [TARGET]) # Validate required columns\n",
    "missing = [col for col in needed if col not in car_data.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns: {missing}\")\n",
    "print(f\"\\nAll required columns found ({len(car_data.columns)} total).\")\n",
    "\n",
    "for col in NUMERIC + [TARGET]: # Convert numeric columns\n",
    "    car_data[col] = pd.to_numeric(car_data[col], errors=\"coerce\")\n",
    "\n",
    "##########class\n",
    "hp = pd.to_numeric(car_data[\"engine_hp\"], errors=\"coerce\")\n",
    "mask = hp.notna()\n",
    "car_data[TARGET_CLS] = pd.qcut(hp[mask], q=3, labels=[\"Economy\", \"Mid\", \"Sport\"])\n",
    "car_data = car_data.dropna(subset=[TARGET_CLS])\n",
    "print(\"\\nclass Target \",car_data[TARGET_CLS].value_counts())\n",
    "######\n",
    "\n",
    "car_data = car_data.dropna(subset=[TARGET]) # Drop rows with missing target\n",
    "print(f\"\\nTarget '{TARGET}' cleaned. Remaining rows: {len(car_data):,}\")\n",
    "\n",
    "for col in CATEGORICAL: # Fill missing categorical values\n",
    "    car_data[col] = car_data[col].fillna(\"\")\n",
    "\n",
    "for col in [\"year\", \"engine_cylinders\", \"number_of_doors\", \"popularity\"]: # Convert certain columns to Int64\n",
    "    if col in car_data.columns:\n",
    "        car_data[col] = pd.to_numeric(car_data[col], errors=\"coerce\").round().astype(\"Int64\")\n",
    "\n",
    "original_cols = set(car_data.columns) # Feature engineering\n",
    "car_data[\"combined_mpg\"] = (car_data[\"city_mpg\"] + car_data[\"highway_mpg\"]) / 2.0\n",
    "den = car_data[\"engine_cylinders\"].replace({0: np.nan})\n",
    "car_data[\"hp_per_cyl\"] = (car_data[\"engine_hp\"] / den).replace([np.inf, -np.inf], np.nan)\n",
    "car_data[\"drivetrain_simple\"] = (car_data[\"driven_wheels\"].astype(str) .str.extract(r\"(front|rear|all)\", expand=False).fillna(car_data[\"driven_wheels\"].astype(str)))\n",
    "\n",
    "num_cols = NUMERIC + [\"combined_mpg\", \"hp_per_cyl\"]\n",
    "cat_cols = CATEGORICAL + [\"drivetrain_simple\"]\n",
    "new_features = sorted(set(car_data.columns) - original_cols)\n",
    "print (f\"\\nFeature engineering complete.\\n new Features {new_features}\")\n",
    "\n",
    "# Remove top 1% price outliers\n",
    "upper_limit = car_data[\"msrp\"].quantile(0.99)\n",
    "car_data = car_data[car_data[\"msrp\"] <= upper_limit]\n",
    "print(f\"\\nAfter outlier removal: {len(car_data):,} rows\")\n",
    "\n",
    "# Add log-transformed target\n",
    "car_data[\"log_msrp\"] = np.log1p(car_data[\"msrp\"])\n",
    "\n",
    "# ---------- 2. Strengthen features ----------\n",
    "car_data[\"hp_x_year\"] = car_data[\"engine_hp\"] * car_data[\"year\"]\n",
    "car_data[\"mpg_ratio\"] = car_data[\"highway_mpg\"] / (car_data[\"city_mpg\"] + 1)\n",
    "car_data[\"hp_per_door\"] = car_data[\"engine_hp\"] / (car_data[\"number_of_doors\"] + 1)\n",
    "car_data[\"is_luxury\"] = car_data[\"market_category\"].str.contains(\"Luxury\", case=False, na=False).astype(int) # Premium indicators\n",
    "car_data[\"is_suv\"] = car_data[\"vehicle_style\"].str.contains(\"SUV\", case=False, na=False).astype(int)\n",
    "car_data[\"is_performance\"] = car_data[\"market_category\"].str.contains(\"Performance\", case=False, na=False).astype(int)\n",
    "top_makes = car_data[\"make\"].value_counts().nlargest(15).index # Group rare makes\n",
    "car_data[\"make_grouped\"] = car_data[\"make\"].where(car_data[\"make\"].isin(top_makes), \"Other\")\n",
    "\n",
    "class ToDenseTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X.toarray() if hasattr(X, \"toarray\") else X\n",
    "\n",
    "X = car_data.drop(columns=[\"msrp\", \"log_msrp\"])\n",
    "y = car_data[\"log_msrp\"]\n",
    "y_cls = car_data[TARGET_CLS]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_STATE)\n",
    "\n",
    "X_cls_train, X_cls_test, y_cls_train, y_cls_test = train_test_split(X, y_cls, test_size=0.3, stratify=y_cls, random_state=RANDOM_STATE)    \n",
    "\n",
    "# --- Prevent target leakage by removing horsepower-based columns ---\n",
    "leakage_features = [\"engine_hp\", \"hp_per_cyl\", \"hp_x_year\"]\n",
    "X_cls_train = X_cls_train.drop(columns=leakage_features, errors=\"ignore\")\n",
    "X_cls_test = X_cls_test.drop(columns=leakage_features, errors=\"ignore\")\n",
    "\n",
    "\n",
    "NUMERIC_CLS = [c for c in NUMERIC if c in X_cls_train.columns and c not in leakage_features]\n",
    "CATEGORICAL_CLS = [c for c in CATEGORICAL if c in X_cls_train.columns]\n",
    "\n",
    "print(f\"\\nRemoved leakage features for classification: {leakage_features}\")\n",
    "print(f\"\\nClassification training shape:  X_cls_train = {X_cls_train.shape}, y_cls_train = {y_cls_train.shape}\")\n",
    "print(f\"Classification testing shape:   X_cls_test  = {X_cls_test.shape},  y_cls_test  = {y_cls_test.shape}\")\n",
    "print(f\"Regression training shape:      X_train     = {X_train.shape}, y_train     = {y_train.shape}\")\n",
    "print(f\"Regression testing shape:       X_test      = {X_test.shape},  y_test      = {y_test.shape}\")\n",
    "\n",
    "print(\"\\nData preparation completed successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b918050e",
   "metadata": {},
   "source": [
    "# **PIPELINE BUILT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "97f52e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pipelines built successfully.\n",
      "   Total features (numeric + categorical): 15\n"
     ]
    }
   ],
   "source": [
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "preprocessor_reg = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, NUMERIC),\n",
    "    (\"cat\", categorical_transformer, CATEGORICAL)\n",
    "])\n",
    "\n",
    "preprocessor_cls = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, NUMERIC_CLS),\n",
    "    (\"cat\", categorical_transformer, CATEGORICAL_CLS)\n",
    "])\n",
    "\n",
    "model_reg = Pipeline([\n",
    "    (\"preprocessor\", preprocessor_reg),\n",
    "    (\"regressor\", LinearRegression())\n",
    "])\n",
    "\n",
    "model_cls = Pipeline([\n",
    "    (\"preprocessor\", preprocessor_cls),\n",
    "    (\"clf\", LogisticRegression(max_iter=5000, random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "model_cls_2 = Pipeline([\n",
    "    (\"preprocessor\", preprocessor_cls),\n",
    "    (\"to_dense\", ToDenseTransformer()),\n",
    "    (\"clf\", LinearDiscriminantAnalysis())\n",
    "])\n",
    "\n",
    "print(\"\\nPipelines built successfully.\")\n",
    "print(f\"   Total features (numeric + categorical): {len(NUMERIC) + len(CATEGORICAL)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65867c21",
   "metadata": {},
   "source": [
    "# **SELECTING AND TRAINING MODEL WITH BEST PARAMS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e794d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No saved regressor found — training regression models...\n",
      "\n",
      "================= REGRESSION RESULTS =================\n",
      "\n",
      " Training TraditionalFamily ...\n",
      "   TraditionalFamily Results:\n",
      "   Best Params: {'preprocessor__num__imputer': SimpleImputer(strategy='median'), 'preprocessor__num__scaler': RobustScaler(), 'regressor': KNeighborsRegressor(), 'regressor__n_neighbors': 3, 'regressor__weights': 'distance'}\n",
      "   Regressor: KNeighborsRegressor\n",
      "   Kernel: N/A\n",
      "   RMSE: 5506.73\n",
      "   MAE:  2964.11\n",
      "   R²:   0.975\n",
      "\n",
      " Training SVR-Bayesian ...\n",
      "   SVR-Bayesian Results:\n",
      "   Best Params: OrderedDict({'regressor': SVR(cache_size=2000, max_iter=25000), 'regressor__C': 436.51583224016565, 'regressor__coef0': 0.0, 'regressor__degree': 2, 'regressor__epsilon': 0.08, 'regressor__gamma': 'scale'})\n",
      "   Regressor: SVR\n",
      "   Kernel: rbf\n",
      "   RMSE: 5533.41\n",
      "   MAE:  3069.24\n",
      "   R²:   0.974\n",
      "\n",
      "===== REGRESSION MODEL COMPARISON =====\n",
      "Model                | Regressor            | Kernel     |       RMSE |        MAE |     R²\n",
      "--------------------------------------------------------------------------------\n",
      "TraditionalFamily    | KNeighborsRegressor  | N/A        |    5506.73 |    2964.11 |  0.975\n",
      "SVR-Bayesian         | SVR                  | rbf        |    5533.41 |    3069.24 |  0.974\n",
      "\n",
      "Best Regressor: TraditionalFamily (KNeighborsRegressor) with R²=0.97 saved to models/best_regressor.joblib\n",
      "\n",
      "No saved classifier found — training classification models...\n",
      "\n",
      "================= CLASSIFICATION RESULTS =================\n",
      "\n",
      " Training GridSearch_LogReg_KNN ...\n",
      "   GridSearch_LogReg_KNN (KNeighborsClassifier) Results:\n",
      "   Best Params: {'clf': KNeighborsClassifier(), 'clf__n_neighbors': 3, 'clf__weights': 'distance', 'preprocessor__num__imputer': SimpleImputer(strategy='median'), 'preprocessor__num__scaler': StandardScaler()}\n",
      "   Accuracy: 0.97 | F1_macro: 0.97 | Kernel: N/A\n",
      "\n",
      "   Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Economy      0.982     0.981     0.981      1214\n",
      "         Mid      0.954     0.962     0.958      1162\n",
      "       Sport      0.981     0.973     0.977      1142\n",
      "\n",
      "    accuracy                          0.972      3518\n",
      "   macro avg      0.972     0.972     0.972      3518\n",
      "weighted avg      0.972     0.972     0.972      3518\n",
      "\n",
      "\n",
      " Training GridSearch_LDA_QDA_NB ...\n",
      "   GridSearch_LDA_QDA_NB (LinearDiscriminantAnalysis) Results:\n",
      "   Best Params: {'clf': LinearDiscriminantAnalysis(), 'clf__solver': 'lsqr'}\n",
      "   Accuracy: 0.94 | F1_macro: 0.94 | Kernel: N/A\n",
      "\n",
      "   Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Economy      0.947     0.951     0.949      1214\n",
      "         Mid      0.896     0.911     0.904      1162\n",
      "       Sport      0.965     0.944     0.954      1142\n",
      "\n",
      "    accuracy                          0.936      3518\n",
      "   macro avg      0.936     0.936     0.936      3518\n",
      "weighted avg      0.936     0.936     0.936      3518\n",
      "\n",
      "\n",
      " Training BayesSearch_SVM ...\n",
      "   BayesSearch_SVM (SVC) Results:\n",
      "   Best Params: OrderedDict({'clf': SVC(cache_size=2000, max_iter=25000, probability=True), 'clf__C': 331.1733327754671, 'clf__coef0': 2.4823335179835837, 'clf__degree': 5, 'clf__gamma': 'scale'})\n",
      "   Accuracy: 0.98 | F1_macro: 0.98 | Kernel: rbf\n",
      "\n",
      "   Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Economy      0.985     0.986     0.986      1214\n",
      "         Mid      0.970     0.976     0.973      1162\n",
      "       Sport      0.991     0.984     0.988      1142\n",
      "\n",
      "    accuracy                          0.982      3518\n",
      "   macro avg      0.982     0.982     0.982      3518\n",
      "weighted avg      0.982     0.982     0.982      3518\n",
      "\n",
      "\n",
      "===== CLASSIFICATION MODEL COMPARISON =====\n",
      "Model                     | Classifier           | Kernel     |   Accuracy |   F1_macro\n",
      "--------------------------------------------------------------------------------\n",
      "GridSearch_LogReg_KNN     | KNeighborsClassifier | N/A        |       0.97 |       0.97\n",
      "GridSearch_LDA_QDA_NB     | LinearDiscriminantAnalysis | N/A        |       0.94 |       0.94\n",
      "BayesSearch_SVM           | SVC                  | rbf        |       0.98 |       0.98\n",
      "\n",
      "Best Classifier: BayesSearch_SVM (SVC) with Accuracy=0.98 saved to models/best_classifier.joblib\n",
      "\n",
      "Leaderboard saved at: reports/leaderboards.json\n",
      "\n",
      "Best models ready for use:\n",
      "   Regressor: models/best_regressor.joblib\n",
      "   Classifier: models/best_classifier.joblib\n"
     ]
    }
   ],
   "source": [
    "\n",
    "GRID_PARAM_CLS = [\n",
    "    {\n",
    "        \"preprocessor__num__imputer\": [SimpleImputer(strategy=\"median\")],\n",
    "        \"preprocessor__num__scaler\": [StandardScaler(), RobustScaler()],\n",
    "        \"clf\": [LogisticRegression(max_iter=5000, random_state=RANDOM_STATE)],\n",
    "        \"clf__C\": LOGREG_C,\n",
    "        \"clf__solver\": LOGREG_SOLVER,\n",
    "        \"clf__penalty\": LOGREG_PENALTY\n",
    "    },\n",
    "    {\n",
    "        \"preprocessor__num__imputer\": [SimpleImputer(strategy=\"median\")],\n",
    "        \"preprocessor__num__scaler\": [StandardScaler()],\n",
    "        \"clf\": [KNeighborsClassifier()],\n",
    "        \"clf__n_neighbors\": [3, 5, 7, 11],\n",
    "        \"clf__weights\": [\"uniform\", \"distance\"]\n",
    "    },\n",
    "]\n",
    "\n",
    "GRID_PARAM_CLS_2 = [\n",
    "    {\"clf\": [LinearDiscriminantAnalysis()], \"clf__solver\": LDA_SOLVER},\n",
    "    {\"clf\": [QuadraticDiscriminantAnalysis()], \"clf__reg_param\": QDA_REG_PARAM},\n",
    "    {\"clf\": [GaussianNB()]},\n",
    "]\n",
    "\n",
    "BAYES_PARAM_SPACE_CLS = {\n",
    "    \"clf\": Categorical([\n",
    "        SVC(kernel=\"linear\", probability=True, max_iter=MAX_ITER, cache_size=CACHE_SIZE),\n",
    "        SVC(kernel=\"rbf\", probability=True, max_iter=MAX_ITER, cache_size=CACHE_SIZE),\n",
    "        SVC(kernel=\"poly\", probability=True, max_iter=MAX_ITER, cache_size=CACHE_SIZE)\n",
    "    ]),\n",
    "    \"clf__C\": Real(1e-3, 1e3, prior=\"log-uniform\"),\n",
    "    \"clf__gamma\": Categorical([\"scale\", \"auto\"]),\n",
    "    \"clf__degree\": Integer(2, 5),\n",
    "    \"clf__coef0\": Real(0.0, 5.0)\n",
    "}\n",
    "\n",
    "GRID_PARAM = [\n",
    "    {\n",
    "        \"preprocessor__num__imputer\": [SimpleImputer(strategy=\"median\"), KNNImputer(n_neighbors=5)],\n",
    "        \"preprocessor__num__scaler\": [StandardScaler(), RobustScaler(), PowerTransformer()],\n",
    "        \"regressor\": [Ridge(), Lasso()],\n",
    "        \"regressor__alpha\": ALPHA\n",
    "    },\n",
    "    {\n",
    "        \"preprocessor__num__imputer\": [SimpleImputer(strategy=\"median\"), KNNImputer(n_neighbors=5)],\n",
    "        \"preprocessor__num__scaler\": [StandardScaler(), MinMaxScaler(), RobustScaler()],\n",
    "        \"regressor\": [LinearRegression()]\n",
    "    },\n",
    "    {\n",
    "        \"preprocessor__num__imputer\": [KNNImputer(n_neighbors=5), SimpleImputer(strategy=\"median\")],\n",
    "        \"preprocessor__num__scaler\": [MinMaxScaler(), RobustScaler()],\n",
    "        \"regressor\": [KNeighborsRegressor()],\n",
    "        \"regressor__n_neighbors\": N_NEIGHBORS,\n",
    "        \"regressor__weights\": WEIGHTS\n",
    "    },\n",
    "]\n",
    "\n",
    "BAYES_PARAM_SPACE = {\n",
    "    \"regressor\": Categorical([\n",
    "        SVR(kernel=\"linear\", max_iter=MAX_ITER, cache_size=CACHE_SIZE),\n",
    "        SVR(kernel=\"poly\", max_iter=MAX_ITER, cache_size=CACHE_SIZE),\n",
    "        SVR(kernel=\"rbf\", max_iter=MAX_ITER, cache_size=CACHE_SIZE)\n",
    "    ]),\n",
    "    \"regressor__C\": COEF,\n",
    "    \"regressor__epsilon\": EPSILON,\n",
    "    \"regressor__gamma\": GAMMA,\n",
    "    \"regressor__degree\": DEGREE,\n",
    "    \"regressor__coef0\": COEF0\n",
    "}\n",
    "\n",
    "models_reg = {\n",
    "    \"TraditionalFamily\": GridSearchCV(\n",
    "        estimator=model_reg, param_grid=GRID_PARAM,\n",
    "        cv=CV5, scoring=SCORE_REG, n_jobs=-1, refit=True\n",
    "    ),\n",
    "    \"SVR-Bayesian\": BayesSearchCV(\n",
    "        estimator=model_reg, search_spaces=BAYES_PARAM_SPACE,\n",
    "        n_iter=N_ITER, cv=CV5, n_jobs=-1, scoring=SCORE_REG,\n",
    "        random_state=RANDOM_STATE, refit=True\n",
    "    )\n",
    "}\n",
    "\n",
    "models_cls = {\n",
    "    \"GridSearch_LogReg_KNN\": GridSearchCV(\n",
    "        estimator=model_cls, param_grid=GRID_PARAM_CLS,\n",
    "        cv=CV5, scoring=SCORE_CLA, n_jobs=-1\n",
    "    ),\n",
    "    \"GridSearch_LDA_QDA_NB\": GridSearchCV(\n",
    "        estimator=model_cls_2, param_grid=GRID_PARAM_CLS_2,\n",
    "        cv=CV5, scoring=SCORE_CLA, n_jobs=-1\n",
    "    ),\n",
    "    \"BayesSearch_SVM\": BayesSearchCV(\n",
    "        estimator=model_cls, search_spaces=BAYES_PARAM_SPACE_CLS,\n",
    "        n_iter=N_ITER, cv=CV, n_jobs=-1, scoring=SCORE_CLA,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "}\n",
    "\n",
    "os.makedirs(os.path.dirname(BEST_REGRESSOR_PATH), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(LEADERBOARD_PATH), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(LEADERBOARD_PATH), exist_ok=True)\n",
    "\n",
    "best_regressor = None\n",
    "best_classifier = None\n",
    "results_reg, results_cls = {}, {}\n",
    "\n",
    "if os.path.exists(BEST_REGRESSOR_PATH):\n",
    "    print(\"\\nFound existing best regressor — skipping regression retraining.\")\n",
    "    best_regressor = joblib.load(BEST_REGRESSOR_PATH)\n",
    "else:\n",
    "    print(\"\\nNo saved regressor found — training regression models...\")\n",
    "\n",
    "    print(\"\\n================= REGRESSION RESULTS =================\")\n",
    "    for name, search in models_reg.items():\n",
    "        print(f\"\\n Training {name} ...\")\n",
    "        try:\n",
    "            search.fit(X_train, y_train)\n",
    "            best_model = search.best_estimator_\n",
    "\n",
    "            y_pred = np.expm1(best_model.predict(X_test))\n",
    "            y_true = np.expm1(y_test)\n",
    "\n",
    "            rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "            mae = mean_absolute_error(y_true, y_pred)\n",
    "            r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "            reg_name = best_model.named_steps[\"regressor\"].__class__.__name__\n",
    "            kernel = getattr(best_model.named_steps[\"regressor\"], \"kernel\", \"N/A\")\n",
    "\n",
    "            print(f\"   {name} Results:\")\n",
    "            print(f\"   Best Params: {search.best_params_}\")\n",
    "            print(f\"   Regressor: {reg_name}\")\n",
    "            print(f\"   Kernel: {kernel}\")\n",
    "            print(f\"   RMSE: {rmse:.2f}\")\n",
    "            print(f\"   MAE:  {mae:.2f}\")\n",
    "            print(f\"   R²:   {r2:.3f}\")\n",
    "\n",
    "            results_reg[name] = {\n",
    "                \"Regressor\": reg_name,\n",
    "                \"RMSE\": rmse,\n",
    "                \"MAE\": mae,\n",
    "                \"R2\": r2,\n",
    "                \"Kernel\": kernel\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\" {name} failed due to: {e}\")\n",
    "\n",
    "    if results_reg:\n",
    "        print(\"\\n===== REGRESSION MODEL COMPARISON =====\")\n",
    "        print(f\"{'Model':<20} | {'Regressor':<20} | {'Kernel':<10} | {'RMSE':>10} | {'MAE':>10} | {'R²':>6}\")\n",
    "        print(\"-\" * 80)\n",
    "        for name, res in results_reg.items():\n",
    "            print(f\"{name:<20} | {res['Regressor']:<20} | {res['Kernel']:<10} | \"\n",
    "                  f\"{res['RMSE']:>10.2f} | {res['MAE']:>10.2f} | {res['R2']:>6.3f}\")\n",
    "    else:\n",
    "        print(\" No regression results available.\")\n",
    "        raise RuntimeError(\"Regression training failed — no valid models produced.\")\n",
    "\n",
    "    best_reg_name, best_reg = max(results_reg.items(), key=lambda x: x[1][\"R2\"])\n",
    "    best_regressor = models_reg[best_reg_name].best_estimator_\n",
    "    joblib.dump(best_regressor, BEST_REGRESSOR_PATH)\n",
    "    print(f\"\\nBest Regressor: {best_reg_name} ({best_reg['Regressor']}) with R²={best_reg['R2']:.2f} saved to {BEST_REGRESSOR_PATH}\")\n",
    "\n",
    "\n",
    "if os.path.exists(BEST_CLASSIFIER_PATH):\n",
    "    print(\"\\nFound existing best classifier — skipping classification retraining.\")\n",
    "    best_classifier = joblib.load(BEST_CLASSIFIER_PATH)\n",
    "else:\n",
    "    print(\"\\nNo saved classifier found — training classification models...\")\n",
    "\n",
    "    print(\"\\n================= CLASSIFICATION RESULTS =================\")\n",
    "    for name, search in models_cls.items():\n",
    "        print(f\"\\n Training {name} ...\")\n",
    "        try:\n",
    "            search.fit(X_cls_train, y_cls_train)\n",
    "            best_model = search.best_estimator_\n",
    "\n",
    "            clf_name = best_model.named_steps[\"clf\"].__class__.__name__\n",
    "            kernel = getattr(best_model.named_steps[\"clf\"], \"kernel\", \"N/A\")\n",
    "\n",
    "            y_pred = best_model.predict(X_cls_test)\n",
    "            acc = accuracy_score(y_cls_test, y_pred)\n",
    "            f1 = f1_score(y_cls_test, y_pred, average=\"macro\")\n",
    "\n",
    "            print(f\"   {name} ({clf_name}) Results:\")\n",
    "            print(f\"   Best Params: {search.best_params_}\")\n",
    "            print(f\"   Accuracy: {acc:.2f} | F1_macro: {f1:.2f} | Kernel: {kernel}\")\n",
    "            print(\"\\n   Classification report:\")\n",
    "            print(classification_report(y_cls_test, y_pred, digits=3))\n",
    "\n",
    "            results_cls[name] = {\n",
    "                \"Classifier\": clf_name,\n",
    "                \"Accuracy\": acc,\n",
    "                \"F1_macro\": f1,\n",
    "                \"Kernel\": kernel\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\" {name} failed due to: {e}\")\n",
    "\n",
    "    if results_cls:\n",
    "        print(\"\\n===== CLASSIFICATION MODEL COMPARISON =====\")\n",
    "        print(f\"{'Model':<25} | {'Classifier':<20} | {'Kernel':<10} | {'Accuracy':>10} | {'F1_macro':>10}\")\n",
    "        print(\"-\" * 80)\n",
    "        for name, res in results_cls.items():\n",
    "            print(f\"{name:<25} | {res['Classifier']:<20} | {res['Kernel']:<10} | \"\n",
    "                  f\"{res['Accuracy']:>10.2f} | {res['F1_macro']:>10.2f}\")\n",
    "    else:\n",
    "        print(\" No classification results available.\")\n",
    "        raise RuntimeError(\"Classification training failed — no valid models produced.\")\n",
    "\n",
    "    best_cls_name, best_cls = max(results_cls.items(), key=lambda x: x[1][\"Accuracy\"])\n",
    "    best_classifier = models_cls[best_cls_name].best_estimator_\n",
    "    joblib.dump(best_classifier, BEST_CLASSIFIER_PATH)\n",
    "    print(f\"\\nBest Classifier: {best_cls_name} ({best_cls['Classifier']}) with Accuracy={best_cls['Accuracy']:.2f} saved to {BEST_CLASSIFIER_PATH}\")\n",
    "\n",
    "leaderboard = {\n",
    "    \"Best Regressor\": best_reg_name if best_regressor else \"Loaded existing model\",\n",
    "    \"Best Regressor Type\": best_reg[\"Regressor\"] if best_regressor else \"Loaded existing model\",\n",
    "    \"Best Regressor R²\": best_reg[\"R2\"] if best_regressor else \"N/A\",\n",
    "    \"Best Classifier\": best_cls_name if best_classifier else \"Loaded existing model\",\n",
    "    \"Best Classifier Type\": best_cls[\"Classifier\"] if best_classifier else \"Loaded existing model\",\n",
    "    \"Best Classifier Accuracy\": best_cls[\"Accuracy\"] if best_classifier else \"N/A\",\n",
    "    \"Regression Results\": results_reg,\n",
    "    \"Classification Results\": results_cls\n",
    "}\n",
    "\n",
    "with open(LEADERBOARD_PATH, \"w\") as f:\n",
    "    json.dump(leaderboard, f, indent=4)\n",
    "\n",
    "print(f\"\\nLeaderboard saved at: {LEADERBOARD_PATH}\")\n",
    "print(\"\\nBest models ready for use:\")\n",
    "print(f\"   Regressor: {BEST_REGRESSOR_PATH}\")\n",
    "print(f\"   Classifier: {BEST_CLASSIFIER_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carPrediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
